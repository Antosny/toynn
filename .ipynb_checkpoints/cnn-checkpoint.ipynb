{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1697, 42)\n",
      "train loss:20.5113407079 eval loss:19.6545267282\n",
      "(1697, 42)\n",
      "train loss:0.368484793092 eval loss:0.703866205814\n",
      "(1697, 42)\n",
      "train loss:0.238472972884 eval loss:0.519355169035\n",
      "(1697, 42)\n",
      "train loss:0.204480297011 eval loss:0.464013192043\n",
      "(1697, 42)\n",
      "train loss:0.191033693011 eval loss:0.430641246484\n",
      "(1697, 42)\n",
      "train loss:0.184067894679 eval loss:0.408347595945\n",
      "(1697, 42)\n",
      "train loss:0.179382738478 eval loss:0.393079875083\n",
      "(1697, 42)\n",
      "train loss:0.175878325136 eval loss:0.381687933082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f3d5754624e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m#out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mpre_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Antosny/Workspace/toynn/utils.pyc\u001b[0m in \u001b[0;36msoftmax_loss\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "from utils import *\n",
    "convweight = []\n",
    "krow = 3\n",
    "kcol = 2\n",
    "kernelsize = 10\n",
    "for i in range(0, kernelsize):\n",
    "    convweight.append(np.random.random(krow * kcol) - 0.5)\n",
    "fcweight = np.random.random((42, 10)) - 0.5\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits['images'][:-100]\n",
    "Y = digits['target'][:-100]\n",
    "X_batch_sum = conv_2d_to_matrix_batch(X, krow, kcol)\n",
    "X_te = digits['images'][-100:]\n",
    "Y_te = digits['target'][-100:]\n",
    "Y_dummy = np.zeros((len(X), 10))\n",
    "for i in range(0, len(X)):\n",
    "    Y_dummy[i, Y[i]] = 1\n",
    "    \n",
    "    \n",
    "def conv_1d_to_2d(data, row, column):\n",
    "    if len(data) != row * column:\n",
    "        return\n",
    "    res = np.zeros((row, column))\n",
    "    for i in range(0, row):\n",
    "        for j in range(0, column):\n",
    "            res[i][j] = data[i*column + j]\n",
    "    return res\n",
    "\n",
    "\n",
    "def conv_2d_to_matrix(data, kernelrow, kernelcol):\n",
    "    mid = []\n",
    "    for xl in range(0, data.shape[0] - kernelrow + 1):\n",
    "        for yl in range(0, data.shape[1] - kernelcol + 1):\n",
    "            mid.append(data[xl:xl+kernelrow, yl:yl+kernelcol].flatten())\n",
    "    return np.array(mid)\n",
    "\n",
    "\n",
    "\n",
    "def conv_2d_to_matrix_batch(data, kernelrow, kernelcol):\n",
    "    mid = []\n",
    "    for single in data:\n",
    "        mid.append(conv_2d_to_matrix(single, kernelrow, kernelcol))\n",
    "    return np.array(mid)\n",
    "\n",
    "def recover_matrix_to_2d(data, row, col):\n",
    "    if (len(data) != row * col):\n",
    "        return\n",
    "    res = np.zeros((row, col))\n",
    "    idx = 0\n",
    "    for i in range(0, row):\n",
    "        for j in range(0, col):\n",
    "            res[i, j] = data[idx]\n",
    "            idx += 1\n",
    "    return res\n",
    "\n",
    "def recover_matrix_to_2d_batch(data, row, col):\n",
    "    res = []\n",
    "    for d in data:\n",
    "        res.append(recover_matrix_to_2d(d, row, col))\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "#2d matrix with kernellist and recover\n",
    "def conv(data, kernellist):\n",
    "    res = None\n",
    "    resrow = data.shape[0] - krow + 1\n",
    "    rescol = data.shape[1] - kcol + 1\n",
    "    kernelmtx = np.sum(kernellist, axis=0)\n",
    "    res = np.dot(conv_2d_to_matrix(data, krow, kcol), kernelmtx)\n",
    "#     ###for kernel in kernellist:\n",
    "#         tmp = np.dot(conv_2d_to_matrix(data, krow, kcol), kernel)\n",
    "#         if res is None:\n",
    "#             res = tmp\n",
    "#         else:\n",
    "#             res += tmp\n",
    "    return recover_matrix_to_2d(res, resrow, rescol)\n",
    "\n",
    "def conv_batch(data, kernellist):\n",
    "    res = []\n",
    "    x_batch_sum = conv_2d_to_matrix_batch(data, krow, kcol)\n",
    "    #print x_batch_sum.shape\n",
    "    resrow = data.shape[0] - krow + 1\n",
    "    rescol = data.shape[1] - kcol + 1\n",
    "    kernelmtx = np.sum(kernellist, axis=0)\n",
    "    return np.tensordot(x_batch_sum, kernelmtx, [2, 0])#.shape\n",
    "\n",
    "def conv_batch_sum(data, data_cov, kernellist):\n",
    "    res = []\n",
    "    #print x_batch_sum.shape\n",
    "    resrow = data.shape[0] - krow + 1\n",
    "    rescol = data.shape[1] - kcol + 1\n",
    "    kernelmtx = np.sum(kernellist, axis=0)\n",
    "    return np.tensordot(data_cov, kernelmtx, [2, 0])#.shape\n",
    "#     for d in data:\n",
    "#         res.append(conv(d, kernellist))\n",
    "#     print np.array(res).shape\n",
    "#     return np.array(res)\n",
    "    \n",
    "\n",
    "def forward(x):\n",
    "    #conv, relu\n",
    "    tmpmtx = relu(conv_batch(x, convweight).reshape(len(x), 42))\n",
    "    #fc\n",
    "    return softmax(np.dot(tmpmtx * (1 - dropoutrate), fcweight))\n",
    "    \n",
    "regu = 0.01\n",
    "    \n",
    "lr = 0.05\n",
    "dropoutrate = 0.0\n",
    "for iter in range(0,3000):\n",
    "    batchsize = len(X)\n",
    "    dropout = np.random.random(42)\n",
    "    dropout[dropout > dropoutrate] = 1\n",
    "    dropout[dropout <= dropoutrate] = 0\n",
    "    for i in range(0, X.shape[0], batchsize):\n",
    "        x_batch = X[i:i+batchsize, :]\n",
    "        y_batch = Y[i:i+batchsize]\n",
    "        y_dummy_batch = Y_dummy[i:i+batchsize, :]\n",
    "        #print 'pre'\n",
    "        x_batch_sum = X_batch_sum[i:i+batchsize]\n",
    "        #print 'batch'\n",
    "        #print 'xbatch'\n",
    "        #print x_batch_sum.shape\n",
    "        #forward\n",
    "        #conv + relu\n",
    "        x_conv = conv_batch_sum(x_batch, x_batch_sum, convweight)#.reshape(len(x_batch), 42)\n",
    "        #print 'conv'\n",
    "        z = relu(x_conv * dropout)\n",
    "\n",
    "        #fc\n",
    "        a2 = (z).dot(fcweight)\n",
    "        #out\n",
    "        pre_batch = softmax(a2)\n",
    "        batch_loss = softmax_loss(pre_batch, y_batch)\n",
    "        if iter % 100 == 0:\n",
    "            print z.shape\n",
    "            print 'train loss:' + str(batch_loss) + ' eval loss:' + str(softmax_loss(forward(X_te), Y_te))\n",
    "        grad_a2 = (pre_batch - y_dummy_batch) / batchsize\n",
    "        grad_w2 = (z.T.dot(grad_a2) + regu * fcweight)\n",
    "        grad_z = grad_a2.dot(fcweight.T)\n",
    "        grad_z_a = z.copy()\n",
    "        grad_z_a[grad_z_a > 0] = 1\n",
    "        grad_z_a[grad_z_a != 1] = 0\n",
    "        #print grad_z.shape\n",
    "        #grad_conv = np.mean((grad_z * grad_z_a).dot(x_batch_sum), axis=0)\n",
    "        grad_conv = np.tensordot(x_batch_sum, (grad_z * grad_z_a), ([0, 1], [0, 1])) / len(x_batch_sum)\n",
    "        fcweight -= lr * grad_w2\n",
    "        for i in range(0, kernelsize):\n",
    "            convweight[i] -= lr * (grad_conv + regu * convweight[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
